{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning: Exploring Clustering and Dimensionality Reduction\n",
    "<img src=\"./materials/logo_cross.png\" style=\"height:100px\"> \n",
    "\n",
    "\n",
    "Welcome to the Hack GT/DSGT collaboration! Our goal at Data Science at Georgia Tech is to teach you about Data Science and Machine Learning in a way that is approachable and useful. We mix theory and hands-on coding -- because it's cool when you can do stuff with your own hands. \n",
    "\n",
    "This notebook accompanies the Unsupervised Learning workshop. Use this notebook to follow along!  \n",
    "\n",
    "Instructions for People New to Notebooks:\n",
    "- *To run a cell, click on a cell and press shift enter.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these packages? \n",
    "- Pandas: Easy data manipulation. Turns data into a spreadsheet-like format (dataframes)  \n",
    "- Numpy: For working with arrays. Useful for efficient mathematical operations  \n",
    "- Matplotlib: To quickly create visualizaitons  \n",
    "- Sklearn: Helps quickly instantiate and train ML models     \n",
    "\n",
    "These are super well documented! If you every have a question, just google!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing fancy functions is easy!\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silencing warnings. because they don't really matter and are just ugly to look at\n",
    "try: \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Clustering\n",
    "<img src=\"./materials/debit-card.png\" style=\"height:50px\">  \n",
    "\n",
    "## We will first look at kMeans and Agglomerative Clustering\n",
    "\n",
    "We will use a shoppping example. We want to cluster users for a recommendaation system.   \n",
    "We need to find groups that may behave similarly. Let's see what data we have  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./shopping_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, [2,3,4]].values #\n",
    "y = data.iloc[:, [1]].values\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans  \n",
    "KMeans is a common initial approach for clustering  \n",
    "Here we see the main 3 steps  \n",
    "1) Import what you need  \n",
    "2) Instantiate your model  \n",
    "3) Fit your model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard flow -- create instance. fit model. use to predict.\n",
    "kmeans= KMeans()\n",
    "kmeans = KMeans(n_clusters=5) \n",
    "kmeans.fit_predict(X)\n",
    "print('prediction and fitting done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: How did we come up with the number of clusters?\n",
    "    \n",
    "Answer: You wouldnt really know. Main ways to guess would be   \n",
    "        1) subject matter expertise   \n",
    "        2) knowing the number of classes upfront (we don't)  \n",
    "        3) Using another algorithm to inform us (we use heirarchical clustering for this next!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X[:,1],X[:,2]) # Which features are these? \n",
    "plt.xlabel('Annual Income', fontsize=15)\n",
    "plt.ylabel('Spending Score', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X[:,1],X[:,2], c=kmeans.labels_, cmap='rainbow')\n",
    "plt.xlabel('Annual Income', fontsize=15), plt.ylabel('Spending Score', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can use the model to predict the identity of a novel input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmeans.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait. What do these classes mean? Think about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering  \n",
    "We can derive clusters and insight into the data through dendrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit the model\n",
    "clustering = AgglomerativeClustering(linkage='ward', n_clusters=5) \n",
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dendrogram. This is fancier but makes a nice image to understand\n",
    "lnk_matrx = linkage(X, 'ward') # {“ward”, “complete”, “average”, “single”}#\n",
    "figure = plt.figure(figsize=(7.5, 5))\n",
    "\n",
    "dendrogram(lnk_matrx, color_threshold=220,\n",
    "           truncate_mode= \"lastp\", p =len(X), leaf_font_size=3) #make the dendrogram and fix aesthetics\n",
    "\n",
    "plt.title('Agglomerative Clustering Dendrogram (Ward)'), plt.xlabel('Sample Index'), plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whoa! We were able to find clusters that describe distinct customer groups. \n",
    "However, consider a case that is more complex. What if you have 10s or even 100s of features? How do you make this data human understandable? How do you visualize? How do you keep from overwhelming your model? \n",
    "\n",
    "For supervised tasks, often a good first approach is a correlation plot or forward feature selection (see slides for more detail here!). Here we can see which features to pluck when training our model\n",
    "\n",
    "<img src=\"./materials/dim_red.png\" style=\"height:300px\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what about more complex clustering Tasks \n",
    "### Think of an image! How many features do we have?  \n",
    "16x16 pizels is 256 features! And what is 256x256...??? \n",
    "\n",
    "<img src=\"./materials/digits.png\" style=\"height:100px\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import. Instantiate. Fit\n",
    "from sklearn import decomposition\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Does this heatmap mean anything to anybody?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(digits.data)\n",
    "plt.matshow(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We talked about PCA in the workshop slides.   \n",
    "But a quick reminder -- PCA does not just select valuable features. PCA looks to define new features that are linear combinations of old features. These new features form new axis that best explain the variation in your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, \n",
    "            edgecolor='none', s=50,\n",
    "            cmap=plt.cm.get_cmap('tab10', 10))\n",
    "plt.colorbar()\n",
    "plt.title('PCA Projection', fontsize=20);\n",
    "plt.xlabel('PC1', fontsize=20), plt.ylabel('PC2', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "Look at this chart. Is this very human interpretable?   \n",
    "Is this machine interpretable -- ex do you think a classifier might be able to use this? \n",
    "How much can we actually tell how well a model could use this.  \n",
    "Think -- how many features did we have? How many features are we looking at? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for an example of finding different solutions to a given task... Let's see if t-SNE works any better!  \n",
    "\n",
    "In a high level sentence -- t-SNE is an itterative approach that finds nonlinear mappings (transformation) from high to low dimensional space. t-SNE looks to keep neighbors in high dim. space neighbors in low dim space. This is done by computing probability distributions in high dim space and trying to best emululate them in the low dimensional representation.\n",
    "Great resource --> \n",
    "https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, instantiate, fit\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=13)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, \n",
    "            edgecolor='none', s=50,\n",
    "            cmap=plt.cm.get_cmap('tab10', 10))\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Out of these two techniques, which would you prefer for this dataset? Why? \n",
    "Think in terms of interpretability and efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun Conclusion Activity\n",
    "Whoa we covered a lot. We probably didn't even get to finish. We all like feeling good about ourselves, so:  \n",
    "Brainstorm a list of what you learned about. Facts? Concepts? Approaches?   \n",
    "**(Double click on this to change in markdown)** \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "## Thank you for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
