{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals of Models and Data   \n",
    "\n",
    "Welcome to Data Science at Georgia Tech! Our goal is to teach you about Data Science and Machine Learning in a way that is useful. We mix theory and hands-on coding -- because it's cool when you can do stuff with your own hands. \n",
    "\n",
    "This notebook accompanies the Fundamental Understandings of Models and Data. Use this notebook to follow along!  \n",
    "\n",
    "Goals: To cover how to consider **models** and **data**\n",
    "\n",
    "Instructions for People New to Notebooks:\n",
    "- To run a cell, click on a cell and press shift enter.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Important Toolkits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silencing warnings. because they don't really matter and are just ugly to look at\n",
    "try: \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 main ways to consider ML models. \n",
    "1) Pictorially  \n",
    "2) Using decision boundaries  \n",
    "3) Mathematically    \n",
    "Let's walk through each of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Pictorially\n",
    "#### Can you guess which picture corresponds to which algorithm?\n",
    "a) KNN b) Neural Network c) Decision Tree d) SVM  \n",
    " \n",
    "<img src=\"./materials/pics.png\" style=\"height:330px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./materials/picture_answers.txt') as f: \n",
    "    for line in f:print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Decision Boundaries\n",
    "####  Now we can plot decision boundaries  \n",
    "Let's quicly use a decision tree, a KNN, an SVM, and a simple neural network   \n",
    "These are all very popular algorithms in industry and in academia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, [0, 1]], iris.target\n",
    "data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifiers\n",
    "dt = DecisionTreeClassifier(max_depth=4)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "svc = SVC(gamma=.1, kernel='rbf', probability=True)\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifiers\n",
    "dt.fit(X, y)  \n",
    "knn.fit(X, y)\n",
    "svc.fit(X, y) \n",
    "mlp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1]),\n",
    "                        [dt, knn, svc, mlp],\n",
    "                        ['Decision Tree (depth=4)', 'KNN (k=7)',\n",
    "                         'Kernel SVM', 'MLP']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(X[:, 0], X[:, 1], c=y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "plt.show()\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_decision_regions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Mathematic Formulations  \n",
    "Lets focus on a regression model. Now we can look at the mathematical formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intuition : linear regression looks something like this: y=mx+b\n",
    "<img src=\"./materials/linear_regression_result-1.png\" style=\"height:250px\">  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets bump up to higher dimensions. We will use thirteen features to predict Boston housing prices   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression model to our data.   \n",
    "There is more than one feature. So y= mx+b is not enough. We need a more complex formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = df, boston.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lm.predict(X_test)\n",
    "print(\"Score is:\",lm.score(X_test,Y_test))\n",
    "\n",
    "my_formatted_list = [ '%.2f' % i for i in lm.coef_ ]\n",
    "str1 = 'x + '.join(str(e) for e in my_formatted_list)\n",
    "print(\"\\n \\nFormula is:\\n y = \", str1, ' + ', str(lm.intercept_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data  \n",
    "There are many potential data forms. Three main categories are sound, image, and tabular data.   \n",
    "Data can also be discrete, catagorical, continuous, and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Tabular\n",
    "\n",
    "from sklearn import datasets\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "print(df.shape)\n",
    "print(data.target_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are these features continuous or discrete? What about the output? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding data. Lets see how an image is represented\n",
    "<img src=\"./materials/buzz.jpg\" style=\"height:200px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "pixel_vals = misc.imread('./materials/pics.png') \n",
    "\n",
    "print(\"size is\", pixel_vals.shape)\n",
    "print(pixel_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun Question: Why are there four dimensions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer: because pngs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide deck continues with discussion of overfitting and underfitting if time permits \n",
    "  \n",
    "   .\n",
    "\n",
    "<img src=\"./materials/fitting.png\" style=\"height:120px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?  \n",
    "Slack a content member or email me at hwhittaker6@gatech.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
