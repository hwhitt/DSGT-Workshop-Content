{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Support Vector Machine) Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is design as a comlementary material for the DSGT workshop.\n",
    "\n",
    "In this notebook, we'll look at the effect and performance of SVM classifiers in supervised learning by finetuning the parameters:\n",
    "\n",
    "- Regularizer/C (how much do we want to avoid misclassification)\n",
    "- Kernel (transformation of data)\n",
    "- Gamma (how far the influence of each data reaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import our sklearn packages for SVM \n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be loading a banknote dataset that involves predicting whether a given banknote is authentic given a number of measures taken from a photograph.\n",
    "\n",
    "It is a binary (2-class) classification problem. There are 1,372 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "- Variance of Wavelet Transformed image (continuous).\n",
    "- Skewness of Wavelet Transformed image (continuous).\n",
    "- Kurtosis of Wavelet Transformed image (continuous).\n",
    "- Entropy of image (continuous).\n",
    "- Class (0 for authentic, 1 for inauthentic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from csv\n",
    "# What pandas function should we call?\n",
    "data = ___________('data_banknote_authentication.csv')\n",
    "\n",
    "# Convert the dataset into DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Classify the banknotes into correct classes (authentic or not)\n",
    "\n",
    "Recall that the correct answer/target/label are given in a supervised learning problem.\n",
    "\n",
    "So, what columns are our features (X)? What are our target (y)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the Variance and Skewness as our features\n",
    "\n",
    "# How can we get extract those two columns from data? \n",
    "# Keyword: slicing\n",
    "X = data.__________\n",
    "\n",
    "#X = StandardScaler().fit_transform(data.iloc[:,0:4])\n",
    "#pca = PCA(n_components = 2)\n",
    "#X = pd.DataFrame(data = pca.fit_transform(X), columns = ['component_1', 'component_2'])\n",
    "\n",
    "# Take a look at the first few rows of X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again, how would you get our y (label) from data\n",
    "# Hint: we need only one column\n",
    "y = data________\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the standard flow of training our model:\n",
    "- CREATE a model instance\n",
    "\n",
    "- FIT your data to it (feed your model the data you want it to learn)\n",
    "\n",
    "- Use the model to PREDICT (show your model data it's never seen and see how well it performs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's shuffle and split our data into training and testing sets (train : test = 8 : 2)\n",
    "X_train ,X_test, Y_train , Y_test = train_test_split(X , y , test_size = 0.2, random_state = 34) # shuffled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance\n",
    "# Let's start with a linear SVC with C = 1 and gamma = 'auto'\n",
    "# How should we pass in the parameters above?\n",
    "classifier1 = svm.SVC(_________________________________)\n",
    "\n",
    "# Fit our data to the model\n",
    "svc1 = classifier1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mesh to plot in\n",
    "x_min, x_max = X_test.iloc[:, 0].min() - 1, X_test.iloc[:, 0].max() + 1 # Max and min for the 1st feature\n",
    "y_min, y_max = X_test.iloc[:, 1].min() - 1, X_test.iloc[:, 1].max() + 1 # Max and min for the 2nd feature\n",
    "x_h = abs(x_max - x_min) / 100 # Divide the range into 100 steps\n",
    "y_h = abs(y_max - y_min) / 100 # Divide \n",
    "xx, yy = np.meshgrid(np.arange(0, abs(x_max - x_min), x_h) - abs(x_min), # Plot the mesh\n",
    "                     np.arange(0, abs(y_max - y_min), y_h) - abs(y_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 1, 1)\n",
    "Z = svc1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Create a contour of the boundary output by our model\n",
    "plt.contourf(xx, yy, Z, cmap = plt.cm.RdYlGn, alpha = 0.8)\n",
    "\n",
    "# Add the data points with correct label color to our contour\n",
    "plt.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c = Y_test, cmap = plt.cm.RdYlGn)\n",
    "\n",
    "# Other elements of our plot\n",
    "plt.xlabel('Variance')\n",
    "plt.ylabel('Skewness')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('SVC with linear kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = svm.SVC(kernel = 'rbf', C = 1, gamma = 'auto')\n",
    "svc2 = classifier2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 1, 1)\n",
    "Z = svc2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap = plt.cm.RdYlGn, alpha = 0.8)\n",
    "plt.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c = Y_test, cmap = plt.cm.RdYlGn)\n",
    "plt.xlabel('Variance')\n",
    "plt.ylabel('Skewness')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('SVC with rbf kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice any difference between linear SVC and rbf SVC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the four: linear, rbf, polynomial, sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper method for graphing the SVM result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_result(svc, ax, title):\n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap = plt.cm.RdYlGn, alpha = 0.8)\n",
    "    ax.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c = Y_test, cmap = plt.cm.RdYlGn)\n",
    "    ax.set_xlabel('Variance')\n",
    "    ax.set_ylabel('Skewness')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the plot for linear, rbf, polynomial, and sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fig that contains four subplots for four different kernels\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize = (14, 10))\n",
    "\n",
    "# ADJUST the parameters here:\n",
    "c = 1\n",
    "g = 'auto' #gamma can also be a numeric value\n",
    "\n",
    "# Create model instance and fit the data\n",
    "svc1 = svm.SVC(kernel = 'linear', C = c, gamma = g).fit(X_train, Y_train)\n",
    "svc2 = svm.SVC(kernel = 'rbf', C = c, gamma = g).fit(X_train, Y_train)\n",
    "svc3 = svm.SVC(kernel = 'poly', C = c, gamma = g).fit(X_train, Y_train)\n",
    "svc4 = svm.SVC(kernel = 'poly', C = c, gamma = g).fit(X_train, Y_train)\n",
    "\n",
    "# Plot linear SVM\n",
    "plot_svm_result(svc1, ax1, 'SVC with linear kernel')\n",
    "\n",
    "# Plot rbf SVM\n",
    "plot_svm_result(svc2, ax2, 'SVC with rbf kernel')\n",
    "\n",
    "# Plot polynomial SVM\n",
    "plot_svm_result(svc3, ax3, 'SVC with polynomial kernel')\n",
    "\n",
    "# Plot sigmoid SVM\n",
    "plot_svm_result(svc4, ax4, 'SVC with sigmoid kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try tuning one of the three parameters (kernel, C, gamma) at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which do you think perform the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "models = [svc1, svc2, svc3, svc4]\n",
    "\n",
    "# Compute the accuracy, recall, precision for four different classifier\n",
    "for model in models:\n",
    "    accuracy.append(accuracy_score(Y_test, model.predict(X_test)))\n",
    "    recall.append(recall_score(Y_test, model.predict(X_test)))\n",
    "    precision.append(precision_score(Y_test, model.predict(X_test)))\n",
    "\n",
    "# Calculate the True Positives, False Positives, False Negatives, and True Negatives\n",
    "metric1 = confusion_matrix(Y_test, svc1.predict(X_test)).ravel()\n",
    "metric2 = confusion_matrix(Y_test, svc2.predict(X_test)).ravel()\n",
    "metric3 = confusion_matrix(Y_test, svc3.predict(X_test)).ravel()\n",
    "metric4 = confusion_matrix(Y_test, svc4.predict(X_test)).ravel()\n",
    "\n",
    "# Put all metrics in one table\n",
    "df = pd.DataFrame({'Kernel': ['linear', 'rbf', 'polynomial', 'sigmoid'], \n",
    "                  'TP': [metric1[0], metric2[0], metric3[0], metric4[0]],\n",
    "                  'FP': [metric1[1], metric2[1], metric3[1], metric4[1]],\n",
    "                  'FN': [metric1[2], metric2[2], metric3[2], metric4[2]],\n",
    "                  'TN': [metric1[3], metric2[3], metric3[3], metric4[3]],\n",
    "                  'accuracy': accuracy,\n",
    "                  'recall': recall,\n",
    "                  'precision': precision})\n",
    "df.set_index('Kernel', inplace = True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
