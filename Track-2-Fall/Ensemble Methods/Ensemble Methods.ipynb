{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods: Overview and Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Online News Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset consisting of various features related to articles online, we want to predict if an article would reach a certain number of shares (hence popular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv file: OnlineNewsPopularity.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Our Features\n",
    "\n",
    "0. url: URL of the article (non-predictive)\n",
    "1. timedelta: Days between the article publication and the dataset acquisition (non-predictive)\n",
    "2. n_tokens_title: Number of words in the title\n",
    "3. n_tokens_content: Number of words in the content\n",
    "4. n_unique_tokens: Rate of unique words in the content\n",
    "5. n_non_stop_words: Rate of non-stop words in the content\n",
    "6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content\n",
    "7. num_imgs: Number of images\n",
    "8. num_videos: Number of videos\n",
    "9. average_token_length: Average length of the words in the content\n",
    "10. num_keywords: Number of keywords in the metadata\n",
    "11. data_channel_is_lifestyle: Is data channel 'Lifestyle'?\n",
    "12. data_channel_is_entertainment: Is data channel 'Entertainment'?\n",
    "13. data_channel_is_bus: Is data channel 'Business'?\n",
    "14. data_channel_is_socmed: Is data channel 'Social Media'?\n",
    "15. data_channel_is_tech: Is data channel 'Tech'?\n",
    "16. data_channel_is_world: Is data channel 'World'?\n",
    "17. kw_min_min: Worst keyword (min. shares)\n",
    "18. kw_max_min: Worst keyword (max. shares)\n",
    "19. kw_avg_min: Worst keyword (avg. shares)\n",
    "20. kw_min_max: Best keyword (min. shares)\n",
    "21. kw_max_max: Best keyword (max. shares)\n",
    "22. kw_avg_max: Best keyword (avg. shares)\n",
    "23. kw_min_avg: Avg. keyword (min. shares)\n",
    "24. kw_max_avg: Avg. keyword (max. shares)\n",
    "25. kw_avg_avg: Avg. keyword (avg. shares)\n",
    "26. self_reference_min_shares: Min. shares of referenced articles in Mashable\n",
    "27. self_reference_max_shares: Max. shares of referenced articles in Mashable\n",
    "28. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable\n",
    "29. weekday_is_monday: Was the article published on a Monday?\n",
    "30. weekday_is_tuesday: Was the article published on a Tuesday?\n",
    "31. weekday_is_wednesday: Was the article published on a Wednesday?\n",
    "32. weekday_is_thursday: Was the article published on a Thursday?\n",
    "33. weekday_is_friday: Was the article published on a Friday?\n",
    "34. weekday_is_saturday: Was the article published on a Saturday?\n",
    "35. weekday_is_sunday: Was the article published on a Sunday?\n",
    "36. is_weekend: Was the article published on the weekend?\n",
    "37. global_subjectivity: Text subjectivity\n",
    "38. global_sentiment_polarity: Text sentiment polarity\n",
    "39. global_rate_positive_words: Rate of positive words in the content\n",
    "40. global_rate_negative_words: Rate of negative words in the content\n",
    "41. rate_positive_words: Rate of positive words among non-neutral tokens\n",
    "42. rate_negative_words: Rate of negative words among non-neutral tokens\n",
    "43. avg_positive_polarity: Avg. polarity of positive words\n",
    "44. min_positive_polarity: Min. polarity of positive words\n",
    "45. max_positive_polarity: Max. polarity of positive words\n",
    "46. avg_negative_polarity: Avg. polarity of negative words\n",
    "47. min_negative_polarity: Min. polarity of negative words\n",
    "48. max_negative_polarity: Max. polarity of negative words\n",
    "49. title_subjectivity: Title subjectivity\n",
    "50. title_sentiment_polarity: Title polarity\n",
    "51. abs_title_subjectivity: Absolute subjectivity level\n",
    "52. abs_title_sentiment_polarity: Absolute polarity level\n",
    "53. shares: Number of shares\n",
    "54. popularity (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unpredictive features: url and timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our data on a simple decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['popularity']\n",
    "data.drop(['popularity'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(random_state = 1)\n",
    "decision_tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = decision_tree_classifier.score(X_train, y_train)\n",
    "test_score = decision_tree_classifier.score(X_test, y_test)\n",
    "\n",
    "print('Training score: ', training_score)\n",
    "print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Finetuning our model with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of parameters to be searched through\n",
    "parameter_grid = {\n",
    "    # Criteria for how we measure the quality of a split.\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 6, 8],\n",
    "    'max_leaf_nodes': [None, 4, 7, 10, 13],\n",
    "}\n",
    "\n",
    "classifier = GridSearchCV(decision_tree_classifier, parameter_grid, cv = 5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_report(classifier):\n",
    "    '''\n",
    "    Generate a report on the performance of the classifier on each combination of parameters.\n",
    "    '''\n",
    "    means = classifier.cv_results_['mean_test_score']\n",
    "    stds = classifier.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    print('Best performing hyperparameters: ', classifier.best_params_)\n",
    "    \n",
    "grid_search_report(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_report(classifier):\n",
    "    '''\n",
    "    Generate a report on how the best classifier performs on the test set.\n",
    "    '''\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print('Accuracy score of best classifier: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "test_accuracy_report(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's apply ensemble learning to make our accuracy better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/bagging.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_classifier = BaggingClassifier(base_estimator = decision_tree_classifier, n_estimators = 100, random_state = 50)\n",
    "bag_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = bag_classifier.score(X_train, y_train)\n",
    "test_score = bag_classifier.score(X_test, y_test)\n",
    "\n",
    "print('Training score: ', training_score)\n",
    "print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: Random Forest = Bagging of decision trees + sampling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/random_forest.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 100, max_depth = 6, criterion = 'entropy', random_state = 50)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = rf_classifier.score(X_train, y_train)\n",
    "test_score = rf_classifier.score(X_test, y_test)\n",
    "\n",
    "print('Training score: ', training_score)\n",
    "print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/adaboost.png\" width = \"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_classifier = AdaBoostClassifier(n_estimators = 100, random_state = 50)\n",
    "ab_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = ab_classifier.score(X_train, y_train)\n",
    "test_score = ab_classifier.score(X_test, y_test)\n",
    "\n",
    "print('Training score: ', training_score)\n",
    "print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/gradient_boosting.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators = 100, max_depth = 6, random_state = 50)\n",
    "gb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = gb_classifier.score(X_train, y_train)\n",
    "test_score = gb_classifier.score(X_test, y_test)\n",
    "\n",
    "print('Training score: ', training_score)\n",
    "print('Test score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What problem do you think our boosting ensemble models have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/stacking.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model, n_fold, train, y, test):\n",
    "    # Divide the training sets into K folds. \n",
    "    # Train the model with 9 folds each time and validate using the 10th fold (remaining fold).\n",
    "    folds = StratifiedKFold(n_splits = n_fold, random_state = 1)\n",
    "    train_pred = np.empty((0,1),float)\n",
    "    \n",
    "    # Iterate Kth times\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        x_train, x_val = train.iloc[train_indices], train.iloc[val_indices]\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "        # Train\n",
    "        model.fit(x_train, y_train)\n",
    "        # Append the validation result of each fold \n",
    "        train_pred = np.append(train_pred, model.predict(x_val))\n",
    "    \n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    # reshape(-1, 1) straightens the matrix to a single column\n",
    "    return train_pred, test_pred.reshape(-1,1), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/stacking_table.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/stacking_table_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0 Model 1: Decision Tree\n",
    "model1 = DecisionTreeClassifier(random_state = 1)\n",
    "\n",
    "train_pred1, test_pred1 = Stacking(model = model1, n_fold = 10, \n",
    "                                   train = X_train, y = y_train, test = X_test)\n",
    "\n",
    "train_pred1 = pd.DataFrame(train_pred1)\n",
    "test_pred1 = pd.DataFrame(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0 Model 2: KNN\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "train_pred2, test_pred2 = Stacking(model = model2, n_fold = 10, \n",
    "                                   train = X_train, y = y_train, test = X_test)\n",
    "\n",
    "train_pred2 = pd.DataFrame(train_pred2)\n",
    "test_pred2 = pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0 Model 3: SVM Classifier\n",
    "model3 = SVC()\n",
    "\n",
    "train_pred3, test_pred3 = Stacking(model = model3, n_fold = 10, \n",
    "                                   train = X_train, y = y_train, test = X_test)\n",
    "\n",
    "train_pred3 = pd.DataFrame(train_pred3)\n",
    "test_pred3 = pd.DataFrame(test_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results of Model 1 to 3 together\n",
    "df = pd.concat([train_pred1, train_pred2, train_pred3], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2, test_pred3], axis=1)\n",
    "\n",
    "# Use logistic regression as the final meta-model, as we're doing binary classification\n",
    "model = LogisticRegression(random_state = 1)\n",
    "model.fit(df, y_train)\n",
    "model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble methods: bagging, boosting and stacking:<br> https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "- Boosting, Bagging, and Stacking — Ensemble Methods with sklearn and mlens:<br> https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de\n",
    "- Understanding the Bias-Variance Tradeoff:<br> https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
    "- Ensemble Learning — Bagging and Boosting:<br> https://becominghuman.ai/ensemble-learning-bagging-and-boosting-d20f38be9b1e\n",
    "- Ensemble Learning — Bagging, Boosting, Stacking and Cascading Classifiers in Machine Learning using SKLEARN and MLEXTEND libraries:<br> https://medium.com/@saugata.paul1010/ensemble-learning-bagging-boosting-stacking-and-cascading-classifiers-in-machine-learning-9c66cb271674"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
