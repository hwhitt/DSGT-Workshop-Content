{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at the use of optimization for various machine learning applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic elements of optimization:\n",
    "- Variables\n",
    "- Constraints\n",
    "- Function for optimization\n",
    "- Optimization method\n",
    "\n",
    "Because the sklearn methods have built in functions for optimization and optimizers, we will focus on applications for regression and classification while noticing how optimization happens behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Data:\n",
    "<img src=\"Resource/wine.jpg\" width=\"250\">\n",
    "Making wine is pretty interesting, where many different factors play a role in determining the properties of the wine. This dataset presents a chemical and physical analysis of wine from 3 different sources in Italy.<sup>1</sup>\n",
    "\n",
    "<sup>1. Forina, M. et al, PARVUS - An Extendible Package for Data\n",
    "       Exploration, Classification and Correlation. Institute of Pharmaceutical\n",
    "       and Food Analysis and Technologies, Via Brigata Salerno, \n",
    "       16147 Genoa, Italy.</sup>\n",
    "\n",
    "#### Brief description of features:\n",
    "1. Cultivar: source of wine\n",
    "2. Alcohol: alcohol content\n",
    "3. Malic acid (C4H6O5): Found in fruits, contributes sour taste\n",
    "4. Ash: inorganic matter\n",
    "5. Alkalinity of ash: how basic the ash is\n",
    "6. Magnesium: magnesium content, a cofactor in many enzyme systems that regulate biochemical reactions in the body\n",
    "7. Total phenols: natural compounds containing phenol group that contribute to the color and texture in wine\n",
    "8. Flavanoids: a type of phenol, most of the phenols in wine are flavanoids\n",
    "9. Nonflavanoid phenols: all the other phenols\n",
    "10. Proanthocyanidins: polyphenols, composed of flavanoid oligomers\n",
    "11. Color intensity: measurement made with spectrophotometer/colorometer to determine transmission properties of the wine\n",
    "12. Hue: a property of color of the wine\n",
    "13. OD280/OD315 of diluted wines: optical density at 280nm/315nm ratio, like absorbance except it considers the scattering of light as well. Used to determine protein concentration\n",
    "14. Proline(C5H9NO2): The most abundant amino acid in wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wine.data',names = ['Cultivar','Alcohol','Malic_acid','Ash','Alkalinity_of_ash','Magnesium',\n",
    "                                 'Total_phenols','Flavanoids','Nonflavanoid_phenols','Proanthocyanidins','Color_intensity',\n",
    "                                 'Hue','OD280/OD315_of_diluted_wines','Proline'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What properties of wine are you interested in? Let's use a heatmap to find relationships between the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap using seaborn:\n",
    "# Helpful settings: square = True, annot = True\n",
    "correlation = df.corr()\n",
    "fig = plt.subplots(figsize=(11,11))\n",
    "sb.heatmap(correlation, square = True, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization for linear regression involves finding the minimum of the mean square error function. This can easily be accomplished with the normal equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our data:\n",
    "x = df[['Flavanoids']]\n",
    "y = df[['OD280/OD315_of_diluted_wines']]\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_axes([.1,.1,.8,.8])\n",
    "ax.scatter(x,y)\n",
    "ax.set_xlabel('Flavanoids')\n",
    "ax.set_ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
    "\n",
    "# Perform linear regression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x_train,y_train)\n",
    "y_pred = linreg.predict(x_test)\n",
    "\n",
    "# Check how we did:\n",
    "accuracy = linreg.score(x_test,y_test)\n",
    "print(\"accuracy:           \", accuracy)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"mean squared error: \", mse)\n",
    "\n",
    "# plot our results:\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_axes([.1,.1,.8,.8])\n",
    "ax.scatter(x,y)\n",
    "ax.plot(x_test,y_pred,'r')\n",
    "ax.set_xlabel('Flavanoids')\n",
    "ax.set_ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which of the three sources the wine is from\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_axes([.1,.1,.8,.8])\n",
    "ax.scatter(df.Flavanoids, df['OD280/OD315_of_diluted_wines'], c=df.Cultivar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "ax.set_xlabel('Flavanoids')\n",
    "ax.set_ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training sets:\n",
    "X = df[['Flavanoids','OD280/OD315_of_diluted_wines']]\n",
    "Y = df['Cultivar']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y)\n",
    "\n",
    "# Fit the data:\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')   #Notice the solver settings\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Results:\n",
    "training_score = logreg.score(X_train, Y_train)\n",
    "print(\"training score: \",training_score)\n",
    "test_score = logreg.score(X_test, Y_test)\n",
    "print(\"test score:     \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data:\n",
    "# Plot the decision boundary in a mesh:\n",
    "x_min, x_max = X['Flavanoids'].min() - .5, X['Flavanoids'].max() + .5\n",
    "y_min, y_max = X['OD280/OD315_of_diluted_wines'].min() - .5, X['OD280/OD315_of_diluted_wines'].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot the points:\n",
    "plt.scatter(df.Flavanoids, df['OD280/OD315_of_diluted_wines'], c=df.Cultivar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Flavanoids')\n",
    "plt.ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets observe the different types of solvers:\n",
    "1. Newton-Conjugate Gradient: 'newton-cg’\n",
    "2. Limited-memory Broyden–Fletcher–Goldfarb–Shanno: ‘lbfgs’\n",
    "3. A Library for Large Linear Classification: ‘liblinear’\n",
    "4. Stochastic gradient Average: ‘sag’, \n",
    "5. SAGA: ‘saga’\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data:\n",
    "clf = svm.SVC(C = 1, gamma = 'auto')   #for SVM, 'liblinear' is used for all computations\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Results:\n",
    "training_score = clf.score(X_train, Y_train)\n",
    "print(\"training score: \",training_score)\n",
    "test_score = clf.score(X_test, Y_test)\n",
    "print(\"test score:     \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary in a mesh:\n",
    "x_min, x_max = X['Flavanoids'].min() - .5, X['Flavanoids'].max() + .5\n",
    "y_min, y_max = X['OD280/OD315_of_diluted_wines'].min() - .5, X['OD280/OD315_of_diluted_wines'].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot the points:\n",
    "plt.scatter(df.Flavanoids, df['OD280/OD315_of_diluted_wines'], c=df.Cultivar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Flavanoids')\n",
    "plt.ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data:\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=1)    #optimization is done by greedy algorithm (usually)\n",
    "decision_tree_classifier.fit(X_train, Y_train)  \n",
    "\n",
    "# Results:\n",
    "training_score = decision_tree_classifier.score(X_train, Y_train)\n",
    "print(\"training score: \",training_score)\n",
    "test_score = clf.score(X_test, Y_test)\n",
    "print(\"test score:     \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary in a mesh:\n",
    "x_min, x_max = X['Flavanoids'].min() - .5, X['Flavanoids'].max() + .5\n",
    "y_min, y_max = X['OD280/OD315_of_diluted_wines'].min() - .5, X['OD280/OD315_of_diluted_wines'].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = decision_tree_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot the points:\n",
    "plt.scatter(df.Flavanoids, df['OD280/OD315_of_diluted_wines'], c=df.Cultivar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Flavanoids')\n",
    "plt.ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data:\n",
    "mlp = MLPClassifier()   # use ‘lbfgs’, ‘sgd’, ‘adam’\n",
    "mlp.fit(X_train,Y_train)\n",
    "\n",
    "# Results:\n",
    "training_score = mlp.score(X_train, Y_train)\n",
    "print(\"training score: \",training_score)\n",
    "test_score = clf.score(X_test, Y_test)\n",
    "print(\"test score:     \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary in a mesh:\n",
    "x_min, x_max = X['Flavanoids'].min() - .5, X['Flavanoids'].max() + .5\n",
    "y_min, y_max = X['OD280/OD315_of_diluted_wines'].min() - .5, X['OD280/OD315_of_diluted_wines'].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot the points:\n",
    "plt.scatter(df.Flavanoids, df['OD280/OD315_of_diluted_wines'], c=df.Cultivar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Flavanoids')\n",
    "plt.ylabel('OD280/OD315_of_diluted_wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does changing the solver effect the end results from using mlp classifier? How does this compare with changing solvers for the logisitic regression?\n",
    "\n",
    "Adjust the learning rate and momentum to see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
