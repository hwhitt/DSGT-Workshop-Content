{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You may (possibly) need to download scipy\n",
    "\n",
    "`pip install scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, uniform, t\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "1. **Central Tendency Measures**\n",
    "\n",
    "**Mean:** The average of the set of observations  \n",
    "**Median:** A measure such that 50% of the data is at or above this value.  \n",
    "**Mode:** The observation with the highest frequency\n",
    "\n",
    "2. **Variability Measures**\n",
    "**Range**: The difference between the maximum and minimum value in the set of observations.  \n",
    "**Variance**: The spread of the observations from the average value.  \n",
    "**Standard Deviation**: The square root of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Median of an array\n",
    "arr = np.random.rand(1, 10)\n",
    "print(\"Contents: \", arr)\n",
    "print(\"Mean: %f\" % arr.mean())\n",
    "print(\"Median: %f\" % np.median(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pop Quiz**: Calculate the range of the array *arr*. (Hint: You can use numpy's built in array.max() and array.min() functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of the array\n",
    "r = arr.max() - arr.min()\n",
    "print('Range: ', r)\n",
    "\n",
    "# Variance of the array\n",
    "print('Variance: ', arr.var())\n",
    "\n",
    "# Standard Deviation of the array\n",
    "print('Standard Deviation: ', arr.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variables in Numpy\n",
    "\n",
    "Notice that numpy's random module actually produces integer value from a random variable's distribution! Shown below is a random array of 10 elements whose contents are sampled from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(3, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(arr, color='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What do you think would happen if we sampled 100 elements instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Sampling Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a Uniform distribution\n",
    "\n",
    "Let's use scipy's out-of-the-box uniform distribution to visualize a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_uniform = uniform.rvs(size=10000, loc =10, scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(data_uniform,\n",
    "                  bins=100,\n",
    "                  kde=True,\n",
    "                  color='skyblue',\n",
    "                  hist_kws={\"linewidth\": 15,'alpha':1})\n",
    "ax.set(xlabel='Uniform Distribution ', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a Uniform distribution\n",
    "\n",
    "Let's use scipy's out-of-the-box normal distribution to visualize a normal distribution  \n",
    "\n",
    "**Pop Quiz**: Using the plot of the uniform distribution as a reference, fill in the parameters of the normal distribution plot to be the following:\n",
    "\n",
    "1. Pass in *data_normal* as the data.\n",
    "2. Make bins=100\n",
    "3. Make the color='skyblue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = norm.rvs(size=10000,loc=0,scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(data_normal,\n",
    "                  bins=100,\n",
    "                  kde=True,\n",
    "                  color='skyblue',\n",
    "                  hist_kws={\"linewidth\": 15,'alpha':1})\n",
    "ax.set(xlabel='Normal Distribution', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of 50 dice rolls 1000 times\n",
    "means = [np.mean(np.random.randint(1, 7, 50)) for _ in range(1000)]\n",
    "# plot the distribution of sample means\n",
    "plt.hist(means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the shape of the distribution? What does it resemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "This is simply a demonstration of calculating 95% confidence intervals for the mean of a t-distribution with unknown standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([63.5, 81.3, 88.9, 63.5, 76.2, 67.3, 66.0, 64.8, 74.9, 81.3, 76.2,\n",
    "        72.4, 76.2, 81.3, 71.1, 80.0, 73.7, 74.9, 76.2, 86.4, 73.7, 81.3,\n",
    "        68.6, 71.1, 83.8, 71.1, 68.6, 81.3, 73.7, 74.9])\n",
    "mean = np.mean(data)\n",
    "\n",
    "# evaluate sample variance by setting delta degrees of freedom (ddof) to\n",
    "# 1. The degree used in calculations is N - ddof\n",
    "stddev = np.std(data, ddof=1)\n",
    "\n",
    "# Get the endpoints of the range that contains 95% of the distribution\n",
    "t_bounds = t.interval(0.95, len(data) - 1)\n",
    "\n",
    "# sum mean to the confidence interval\n",
    "ci = [mean + critval * stddev / np.sqrt(len(data)) for critval in t_bounds]\n",
    "\n",
    "print(\"Mean: %f\" % mean)\n",
    "print(\"Confidence Interval 95%%: %f, %f\" % (ci[0], ci[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources and Additional Readings\n",
    "\n",
    "[Think Stats by Downey](http://greenteapress.com/thinkstats/thinkstats.pdf)  \n",
    "[Hypothesis Testing](https://www.investopedia.com/terms/h/hypothesistesting.asp)  \n",
    "[5 Basic Statistics Concepts for Data Science](https://towardsdatascience.com/the-5-basic-statistics-concepts-data-scientists-need-to-know-2c96740377ae)  \n",
    "[Statistics and Data Science Course](https://www.edx.org/micromasters/mitx-statistics-and-data-science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Exploratory Data Analysis\n",
    "\n",
    "We will apply the concepts we've learned to perform some EDA on a SAT/ACT dataset (data from the past 3 years).\n",
    "\n",
    "# TODO: Insert pop-quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17 = pd.read_csv('./data/sat_2017.csv')\n",
    "sat_18 = pd.read_csv('./data/sat_2018.csv')\n",
    "act_17 = pd.read_csv('./data/act_2017.csv')\n",
    "act_18 = pd.read_csv('./data/act_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Explorations and Cleaning Corrupted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the size of our datasets using the shape attribute. Notice the inconsistency in the dimensions of each year's data!\n",
    "print(\"SAT 2017 Shape: \", sat_17.shape)\n",
    "print(\"SAT 2018 Shape: \", sat_18.shape)\n",
    "print(\"ACT 2017 Shape: \", act_17.shape)\n",
    "print(\"ACT 2018 Shape: \", act_18.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a closer look at the structure of the data. NOTE: We are working with the 2018 ACT data as a point of reference.\n",
    "act_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a look at the frequencies of the states in \n",
    "act_18['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the state of Maine is corrupted or duplicate.\n",
    "act_18[act_18['State'] == 'Maine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate entry\n",
    "act_18.drop(act_18.index[52], inplace=True)\n",
    "\n",
    "# Reset the indices to the updated DataFrame\n",
    "act_18 = act_18.reset_index(drop=True)\n",
    "act_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Pop quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(act_col, sat_col):\n",
    "    '''\n",
    "    Takes in two lists of SAT and ACT statistics and compares the uniqueness of values in each of them.\n",
    "    '''\n",
    "    act_vals = []\n",
    "    sat_vals = []\n",
    "    \n",
    "    for act in act_col:\n",
    "        act_vals.append(act)\n",
    "    \n",
    "    for sat in sat_col:\n",
    "        sat_vals.append(sat)\n",
    "        \n",
    "    print('Values unique to ACT: ')\n",
    "    for act in act_vals:\n",
    "        if act not in sat_vals:\n",
    "            print(act)\n",
    "            \n",
    "    print('----------------------')\n",
    "    \n",
    "    print('Values unique to SAT: ')\n",
    "    for sat in sat_vals:\n",
    "        if sat not in act_vals:\n",
    "            print(sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_values(act_17['State'], sat_17['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_values(act_18['State'], sat_18['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_17[act_17['State'] == 'National']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_17.drop(act_17.index[0], inplace=True)\n",
    "act_17 = act_17.reset_index(drop=True)\n",
    "act_17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_18[act_18['State'] == 'National']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_18.drop(act_18.index[0], inplace=True)\n",
    "act_18 = act_18.reset_index(drop=True)\n",
    "act_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the values are consistent in the 2017 ACT dataframe.\n",
    "print('------ WASHINGTON D.C --------')\n",
    "print(act_17[act_17['State'] == 'Washington, D.C.'])\n",
    "print('------ District of Columbia --------')\n",
    "print(act_17[act_17['State'] == 'District of Columbia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAT 2017 Cols: ', sat_17.columns, '\\n')\n",
    "print('SAT 2018 Cols: ', sat_18.columns, '\\n')\n",
    "print('ACT 2017 Cols: ', act_17.columns, '\\n')\n",
    "print('ACT 2018 Cols: ', act_18.columns, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17.drop(columns = ['Evidence-Based Reading and Writing', 'Math'], inplace = True)\n",
    "act_17.drop(columns = ['English', 'Math', 'Reading', 'Science'], inplace = True)\n",
    "sat_18.drop(columns = ['Evidence-Based Reading and Writing', 'Math'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAT 2017 Cols: ', sat_17.columns, '\\n')\n",
    "print('SAT 2018 Cols: ', sat_18.columns, '\\n')\n",
    "print('ACT 2017 Cols: ', act_17.columns, '\\n')\n",
    "print('ACT 2018 Cols: ', act_18.columns, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAT 2017 Missing Data: ')\n",
    "print(sat_17.isnull().sum(), '\\n')\n",
    "print('SAT 2018 Missing Data: ')\n",
    "print(sat_18.isnull().sum(), '\\n')\n",
    "print('ACT 2017 Missing Data: ')\n",
    "print(act_17.isnull().sum(), '\\n')\n",
    "print('ACT 2018 Missing Data: ')\n",
    "print(act_18.isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAT 2017 Data Types: ')\n",
    "print(sat_17.dtypes, '\\n')\n",
    "print('SAT 2018 Data Types: ')\n",
    "print(sat_18.dtypes, '\\n')\n",
    "print('ACT 2017 Data Types: ')\n",
    "print(act_17.dtypes, '\\n')\n",
    "print('ACT 2018 Data Types: ')\n",
    "print(act_18.dtypes, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
