{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Workshop3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xOOIMrcAy74e","colab_type":"text"},"source":["<img src=\"https://drive.google.com/uc?id=1E_GYlzeV8zomWYNBpQk0i00XcZjhoy3S\" width=\"100\"/>"]},{"cell_type":"markdown","metadata":{"id":"l55hRHepzDhF","colab_type":"text"},"source":["# DSGT Bootcamp Week 3: Feature Manipulation"]},{"cell_type":"markdown","metadata":{"id":"NtWH0UafzI9M","colab_type":"text"},"source":["## Learning Objectives  \n","1)  Handling Missing Values  \n","2)  Row/Column Manipulation  \n","3)  Feature Engineering  \n","4)  Feature Removal  (and feature normalization)    "]},{"cell_type":"markdown","metadata":{"id":"Ath8gMVA1Wmx","colab_type":"text"},"source":["<img src=\"https://miro.medium.com/max/1200/1*K6ctE0RZme0cqMtknrxq8A.png\" width=\"350\">"]},{"cell_type":"markdown","metadata":{"id":"83bTKLHazxSE","colab_type":"text"},"source":["## Setup  \n","First we will mount the drive. Then we will read in our dataset. We will be using pandas again! "]},{"cell_type":"code","metadata":{"id":"0VD1fxEuzdVX","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1UrxirXuzgME","colab_type":"code","colab":{}},"source":["%cd 'drive/My Drive/Track1(AppliedDataScience)/Participants/Data'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xur1_6C90Buw","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6h0CNQ1zrHk","colab_type":"code","colab":{}},"source":["df = pd.read_csv('train.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd0a-_DDzrKd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ln-Fqll0Fzr","colab_type":"text"},"source":["## Why do we need data preprocessing? \n","\n","When you recieve data, there can be a lot to fix.  \n","Potential issues include:   \n","1) Flaws in the data itself (ex poor formatting or missing values)     \n","2) Information could still be added (maybe creating your own features?)  \n","3) Some data may be redundant or not be useful "]},{"cell_type":"markdown","metadata":{"id":"YqMNqRBY0OFk","colab_type":"text"},"source":["# Missing Values & Value Imputation"]},{"cell_type":"markdown","metadata":{"id":"dOfn7cuz1rmM","colab_type":"text"},"source":["<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/How-to-Handle-Missing-Values-with-Python.jpg\" width=\"300px\">"]},{"cell_type":"markdown","metadata":{"id":"mnt02xx5221k","colab_type":"text"},"source":["How would you handle missing values? Many algorithms will not run with NaNs or missing values.   \n","\n","\\\\\n","One approach may be to delete all rows with missing values.   \n","An example is removing all users with a missing field, such as age. However, you could lose a lot of data this way    \n","\n","\\\\\n","**Value Imputation** is an intelligent way of filling  in missing values. The following exercise walks through deleting random values from a few columns and then fixing them using a few different types of imputation. "]},{"cell_type":"code","metadata":{"id":"oyBCS4nj3fsV","colab_type":"code","colab":{}},"source":["# Creating a new dataframe with a subset of columns from the original\n","mini_df = df[['TotalBsmtSF', 'CentralAir', 'GarageArea']]\n","mini_df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUB7iJdC0NUw","colab_type":"code","colab":{}},"source":["# don't worry about this code block. Here we are just generating missing values\n","\n","# remove 20% of data from the features\n","np.random.seed(1)\n","\n","mini_df['TotalBsmtSF'] = \\\n","    mini_df['TotalBsmtSF'].mask(np.random.random(mini_df['TotalBsmtSF'].shape) < .2)\n","\n","mini_df['CentralAir'] = \\\n","    mini_df['CentralAir'].mask(np.random.random(mini_df['CentralAir'].shape) < .2)\n","\n","mini_df['GarageArea'] = \\\n","    mini_df['GarageArea'].mask(np.random.random(mini_df['GarageArea'].shape) < .2)\n","mini_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"exNmW-bcIY8l","colab_type":"code","colab":{}},"source":["# Generating missing values -- used for the purpose of the exercise\n","# Not critical to understand or reproduce!\n","\n","\n","np.random.seed(1)\n","\n","# Filling each of the 3 features with some random values so we can practice\n","# our 3 types of imputation\n","\n","mini_df['TotalBsmtSF'] = \\\n","    mini_df['TotalBsmtSF'].mask(np.random.random(mini_df['TotalBsmtSF'].shape) < .2)\n","\n","mini_df['CentralAir'] = \\\n","    mini_df['CentralAir'].mask(np.random.random(mini_df['CentralAir'].shape) < .2)\n","\n","mini_df['GarageArea'] = \\\n","    mini_df['GarageArea'].mask(np.random.random(mini_df['GarageArea'].shape) < .2)\n","\n","mini_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tMkGIxuo5em3","colab_type":"text"},"source":["What changes were made?"]},{"cell_type":"code","metadata":{"id":"ObJdOSui5d08","colab_type":"code","colab":{}},"source":["mini_df.isnull()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfG39VDczrM8","colab_type":"code","colab":{}},"source":["mini_df.isnull().sum(axis = 0) \n","# Question? Any guesses as to what axis=0 means? "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u1Dkf2dY7_Vc","colab_type":"text"},"source":["## Types of Imputation\n","- Fixed values (all 0s)  \n","- Measures of central tendency (the mean, median, mode of existing entries) \n","- Backfilling (filling with the prior existing value)\n","\n","<img src=\"https://drive.google.com/uc?id=1IB1Tge9wPAqOqH5FcVlLGDDB4nmV4Ddr\" width=\"600\"/>"]},{"cell_type":"code","metadata":{"id":"sHa0Ef-kzrTD","colab_type":"code","colab":{}},"source":["# An example of fixed-value imputation\n","mini_df['CentralAir'].fillna('N', inplace=True) # what does inplace=True mean?\n","\n","mini_df.isnull().sum(axis=0) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmrEkZN38YHd","colab_type":"code","colab":{}},"source":["# An example of mean-imputaiton\n","mini_df['TotalBsmtSF'].fillna(mini_df['TotalBsmtSF'].mean(), inplace=True)\n","\n","# An example of backfill-imputation\n","mini_df['GarageArea'].fillna(method=\"backfill\", inplace=True)\n","\n","mini_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjjEH6JX-lmA","colab_type":"text"},"source":["# Feature Creation\n","We can make features (or columns) from scratch. We can also derive them from existing columns  \n","We can consider feature engineering here as accessing rows and columns of the dataframe"]},{"cell_type":"markdown","metadata":{"id":"bHzzyUot_EPj","colab_type":"text"},"source":["### Editing with Rows"]},{"cell_type":"code","metadata":{"id":"LPxfX7RI8ZP9","colab_type":"code","colab":{}},"source":["# Let's start by viewing the head of the dataframe\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7znOnth_JYU","colab_type":"code","colab":{}},"source":["# Recap: Who remembers what 0 indexing means? \n","df.iloc[2] # This returns a single row, called a series\n","\n","# What row of the dataframe does this return?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ_OBPZI_S4f","colab_type":"code","colab":{}},"source":["# We can chain .iloc with filtering to pick a value at a specific row and column\n","df.iloc[2]['LotFrontage']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggB-ccGw_3lA","colab_type":"code","colab":{}},"source":["# We can also use the assignment operator to change the value in an area\n","# *= is a special variant that multiples the existing value by whatever is on\n","# the right side of the operator\n","df.iloc[2]['LotFrontage'] *= 1.25"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siXA-48UKX5L","colab_type":"text"},"source":["Can you work with your groups to figure out the value of TotalBsmtSF at for the 10th row?"]},{"cell_type":"markdown","metadata":{"id":"sZsk8mGJzJDu","colab_type":"text"},"source":["### Editing with Columns\n","\n","Creating columns is a big part of feature engineering. You can create a column with a chosen value, with a random value, or by changing values of other columns"]},{"cell_type":"code","metadata":{"id":"FiBfcleHzqhv","colab_type":"code","colab":{}},"source":["# creating a column\n","df['New_Column_Chosen_Value'] = 2 # we can choose one constant value\n","df['New_Column_Random_Value'] = np.random.rand() # we can randomly generate a value\n","df['BiggerLotFrontage'] = df['LotFrontage'] + 1  # we can manipulate old columns\n","\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iSfMHzz_BadC","colab_type":"text"},"source":["## Feature Creation Using the \"where\" Syntax  \n","Think of this as a conditional statement: \"Make a change **where** condition\"  \n","For example, we can make a binary feature. \n","We will create feature isLargeLot. You have a large lot **where** large lot > 9500"]},{"cell_type":"code","metadata":{"id":"JN_xjl5jBZ7B","colab_type":"code","colab":{}},"source":["df['isLargeLot'] = 0\n","df['isLargeLot'].where(df[\"LotArea\"] > 9500, 1, inplace=True)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVByLFiiMn3P","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Xm6V2MT0MoEk","colab_type":"code","colab":{}},"source":["# try to create a mini dataframe containing only where MSSubClass == 60 \n","my_df = \n","#        answer: df.where(df['MSSubClass'] == 60)\n","my_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQSYAtnuA7Ek","colab_type":"text"},"source":["We can also derive features from other features. For example, lets make a ratio"]},{"cell_type":"code","metadata":{"id":"1UDrgMigA6iX","colab_type":"code","colab":{}},"source":["df['LotRatio'] = df['LotFrontage'] / df['LotArea']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8S0xQtVmMpFe","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"sBSFsJkjwBj4","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"-Sa6NfznMpQg","colab_type":"code","colab":{}},"source":["# try incrementing all values in the \"LotArea\" by 1\n","df['LotArea'] = \n","# answer  df['LotArea'] + 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n10TJr6AzJHU","colab_type":"text"},"source":["## Non-Useful Data\n","Another data flaw can be that non-useful data may be included.  \n","Why is this a problem?      \n","- You don't get useful information \n","- Information overload can cloud analysis  \n","- Extra information can increase dataset size\n","- Extra information can increase computational overhead   \n","\n","<img src=\"https://drive.google.com/uc?id=1YT_MAY-tkTdXBjq1Z5bgyBSHb0yF77g8\" width=\"500\"/>  \n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6R8ht0NxE8DA","colab_type":"code","colab":{}},"source":["# dropping columns is easy  \n","# we will drop all of the columns we made \n","df.drop(columns=['isLargeLot'], axis=1, inplace=True)\n","df.drop(columns=['New_Column_Chosen_Value', 'New_Column_Random_Value', 'BiggerLotFrontage'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRBdz66gHJqp","colab_type":"text"},"source":["## Testing It Out: The effects of any data manipulation on misc. ML tasks  \n","\n","For example, let's take a look at performance as we run feature selection using simple (one-variable) linear regression \n","\n","<img src=\"https://drive.google.com/uc?id=1MH6qYH3bM8TQ4os6geXhY9HHeD4yXuYk\" width=\"400\"/>\n","\n","\n","We can also choose to run multiple linear regression on any of the features we want. Let's select only useful features, a process known as **feature selection**  \n","\n","<img src=\"https://drive.google.com/uc?id=1gnabMUH4gLyLyPygU56OXZmmZ5LzbNCP\" width=\"690\"/>"]},{"cell_type":"markdown","metadata":{"id":"G1MYGHCFNT8l","colab_type":"text"},"source":["So, what do we have to work with?"]},{"cell_type":"code","metadata":{"id":"x1yXUhWrG5B2","colab_type":"code","colab":{}},"source":["df.columns"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yHY90dhlG83D","colab_type":"text"},"source":["## One Feature"]},{"cell_type":"code","metadata":{"id":"BqfYggY_G5N1","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","lr = LinearRegression()\n","\n","# b=df_housing['LSTAT'].to_numpy()\n","lr.fit(df[['LotArea']], df['SalePrice'])\n","\n","lr.coef_\n","print(lr.score(df[['LotArea']], df['SalePrice']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJQypY7lG-ra","colab_type":"text"},"source":["## Few Features "]},{"cell_type":"code","metadata":{"id":"_-gpVATyHBSe","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","lr = LinearRegression()\n","\n","# b=df_housing['LSTAT'].to_numpy()\n","lr.fit(df[['LotArea', 'GarageArea', 'BsmtFinSF1']], df['SalePrice'])\n","\n","lr.coef_\n","print(lr.score(df[['LotArea','GarageArea', 'BsmtFinSF1']], df['SalePrice']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0G7gyjT-HCMT","colab_type":"text"},"source":["## Many Features"]},{"cell_type":"code","metadata":{"id":"Us_nfH0bHBfk","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","lr = LinearRegression()\n","\n","# b=df_housing['LSTAT'].to_numpy()\n","lr.fit(df[['LotArea', 'GarageArea', 'BsmtFinSF1', \"GarageArea\", 'TotalBsmtSF']], df['SalePrice'])\n","\n","lr.coef_\n","print(lr.score(df[['LotArea','GarageArea', 'BsmtFinSF1', \"GarageArea\", 'TotalBsmtSF']], df['SalePrice']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__nBYNpHObMu","colab_type":"text"},"source":["What do we notice from this?   \n","Here we note diminishing returns as more features are added  \n","We se significant improvements as features are added, but diminishing returns to scale.  \n","These diminishing returns could incur additional overhead, multicollinearity, and other logistical issues. "]},{"cell_type":"code","metadata":{"id":"Q-fHtsv3u0Br","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}